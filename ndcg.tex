\section{NDCG}
\label{sec:ndcg}
For relevance scores, the discounted cumulative gain at $K$ is 
\begin{align*}
  \text{DCG}@K(\sigma, (y_j)_{j=1}^n)
  = \sum_{r=1}^K \frac{G(y_{\sigma^{-1}(r)})}{D(r)}
  = \sum_{i: \sigma(i) \leq K} \frac{G(y_i)}{D(\sigma(i))}.
\end{align*}
(The first sum runs over positions and the second sum runs over
object indices.) The gain function $G$ boosts relevance scores, and is
normally taken to be $G(y) = 2^y - 1$. The discount function $D$ discounts
the importance of the term based on the position of the item, and is
normally taken to be $D(\sigma(i)) = \log(1 + \sigma(i))$. As before, DCG
is the non-truncated version of this, and NDCG normalizes DCG to obtain
a number in $[0,1]$, defined as
\begin{align*}
  \text{NDCG}(\sigma, (y_j)_{j=1}^n)
  = \frac{1}{N((y_j)_{j=1}^n)} DCG(\sigma, (y_j)_{j=1}^n),
\end{align*}
where
\begin{align*}
  N(y) = N((y_j)_{j=1}^n)
  = \frac{1}{\max_{\sigma'} \text{DCG}(\sigma', (y_j)_{j=1}^n)} \text{DCG}(\sigma, (y_j)_{j=1}^n)
\end{align*}
is the normalization factor. 
In many applications, it is more important for the output to rank well for
items that are near the top compared to ones below, and to rank well for
highly relevant items compared to those with low scores; NDCG factors
these in using the discount and gain functions respectively.

If the algorithm is to output a scoring function and has access to relevance
scores as labels, perhaps the simplest idea is to minimize similarity between
the function output and labels; when they are equal, the NCDG is also one.
In~\cite{bayes-optimal-subset-ranking}, it was
established that regression works, in the sense that minimizing the least-squares
surrogate
\begin{align*}
  \phi(\vec{s}, y) = \sum_{j=1}^n {(s_j - y_j)}^2
\end{align*}
actually minimizes $1 - \text{NDCG}(\vec{s}, y)$ because we can upper bound
the latter by some multiple of the former. But this upper bound is coarse, and
the result does not imply consistency. 
Moreover, such a surrogate is pointwise, in the sense
that training is done on individual objects $(x_j, y_j)$, and does not
exploit potential structure in the problem.

In what is termed the pairwise approach, the surrogate loss
$\phi(\vec{s}, y)$ decomposes over pairs of objects rather than single objects
as above:
\begin{align*}
  \phi(\vec{s}, y)
  &\stackrel{\Delta}{=}
  \sum_{j,k : i \neq j} \phi'(s_j - s_k, \text{sign}(y_j - y_k)) 
\end{align*}
for some $\phi'$.
The pairwise approach attempts to reduce the problem of
ranking to the problem of classifying a pair as $\pm 1$ (i.e.,
when an object should be preferred over another). Some choices of $\phi'$
are the hinge loss of Ranking SVM~\cite{ranksvm}
($\phi'(s, y) = \1_{y < 0}(1 - s)_+$),
exponential loss of RankBoost~\cite{rankboost},
and the logistic loss of RankNet~\cite{}.
It is instructive to review how the logistic loss of RankNet is derived.
First, formulate a probabilistic model for the probability
of a pair $(x_j, x_k)$ receiving the label $+1$, based on the function's
output. Then think of the labels $\text{sign}(y_j - y_k)$
for this pair as coming from the underlying distribution that we are learning.
We want the distribution induced by the function's output to be similar to the
underlying distribution, so it makes sense to take $\phi'$ as the KL-divergence
\begin{align*}
  \phi'(s_j - s_k, \text{sign}(y_j - y_k))
  = \text{KL}(\Pr[\text{$(x_j, x_k)$ has label $1$} ; s_j - s_k], \Pr[\text{$(x_j, x_k)$ has label $1$} ; \text{sign}(y_j - y_k)]).
\end{align*}
RankNet uses the probabilistic models
\begin{align*}
  \Pr[\text{$(x_j, x_k)$ has label $+1$}; s_j - s_k] &= \frac{1}{1 + e^{-(s_j - s_k)}} \\
  \Pr[\text{$(x_j, x_k)$ has label $+1$} ; \text{sign}(y_j - y_k)] &=
  \begin{cases}
    1 & \text{sign}(y_j - y_k) = 1 \\
    \frac{1}{2} & \text{sign}(y_j - y_k) = 0 \\
    0 & \text{sign}(y_j - y_k) = -1
  \end{cases}
\end{align*}
(The latter can be changed to a proportion over the training set.)

Work in~\cite{ranking-measures-and-loss-functions} showed that Ranking SVM,
RankBoost, and RankNet all minimize $1 - \text{NDCG}(\vec{s}, y)$, but
Xia et.\ al.\ showed that Ranking SVM and RankBoost are in fact inconsistent,
even under the low-noise assumption~\cite{xia2008listwise}. 

In the listwise approach, the structure of the entire 

Empirical comparisons also show that pointwise
surrogates like these, where training is done on individual objects, are less
accurate than pairwise and listwise surrogates; a pairwise surrogate is of the
form
\begin{align*}
  \phi(\vec{s}, y)
  &\stackrel{\Delta}{=}
  \sum_{j,k : i \neq j} \phi'(s_j - s_k, y_j - y_k) \\
  \phi(\vec{s}, G)
  &\stackrel{\Delta}{=}
  \sum_{j,k : i \neq j} \phi'(s_j - s_k, w_{j,k}^G) 
\end{align*}
for some $\phi'$, i.e., the loss decomposes over pairs.

Moreover, this surrogate is a pointwise surrogate;
when training on this loss, 



Subsequent work showed that
direct regression works~\cite{ndcg-consistency}: 

The idea of making function output and labels similar
also lies behind using cosine similarity~\cite{rank-cosine}, 
However, 


\subsection{LambdaRank}
