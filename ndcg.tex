\section{NDCG}
\label{sec:ndcg}
For relevance scores, the discounted cumulative gain at $K$ is 
\begin{align*}
  \text{DCG}@K(\sigma, (y_j)_{j=1}^n)
  = \sum_{r=1}^K \frac{G(y_{\sigma^{-1}(r)})}{D(r)}
  = \sum_{i: \sigma(i) \leq K} \frac{G(y_i)}{D(\sigma(i))}.
\end{align*}
(The first sum runs over positions and the second sum runs over
object indices.) The gain function $G$ boosts relevance scores, and is
normally taken to be $G(y) = 2^y - 1$. The discount function $D$ discounts
the importance of the term based on the position of the item, and is
normally taken to be $D(\sigma(i)) = \log(1 + \sigma(i))$. As before, DCG
is the non-truncated version of this, and NDCG normalizes DCG to obtain
a number in $[0,1]$, defined as
\begin{align*}
  \text{NDCG}(\sigma, (y_j)_{j=1}^n)
  = \frac{1}{N((y_j)_{j=1}^n)} DCG(\sigma, (y_j)_{j=1}^n),
\end{align*}
where
\begin{align*}
  N(y) = N((y_j)_{j=1}^n)
  = \frac{1}{\max_{\sigma'} \text{DCG}(\sigma', (y_j)_{j=1}^n)} \text{DCG}(\sigma, (y_j)_{j=1}^n)
\end{align*}
is the normalization factor. 
In many applications, it is more important for the output to rank well for
items that are near the top compared to ones below, and to rank well for
highly relevant items compared to those with low scores; NDCG factors
these in using the discount and gain functions respectively.

If the algorithm is to output a scoring function and has access to relevance
scores as labels, perhaps the simplest idea is to minimize similarity between
the function output and labels; when they are equal, the NCDG is also one.
In~\cite{bayes-optimal-subset-ranking}, it was
established that regression works, in the sense that minimizing the least-squares
surrogate
\begin{align*}
  \phi(\vec{s}, y) = \sum_{j=1}^n {(s_j - y_j)}^2
\end{align*}
actually minimizes $1 - \text{NDCG}(\vec{s}, y)$ because we can upper bound
the latter by some multiple of the former. But this upper bound is coarse, and
the result does not imply consistency. 
Moreover, such a surrogate is pointwise, in the sense
that training is done on individual objects $(x_j, y_j)$, and does not
exploit potential structure in the problem.
%In~\cite{ndcg-consistency}, it was shown
%that the normalization factor in NDCG has to be incorporated into the
%surrogate loss in order to be consistent -- the main result is that the
%minimizer of a surrogate loss has to 

In what is termed the pairwise approach, the surrogate loss
$\phi(\vec{s}, y)$ decomposes over pairs of objects rather than single objects
as above:
\begin{align*}
  \phi(\vec{s}, y)
  &\stackrel{\Delta}{=}
  \sum_{j,k : i \neq j} \phi'(s_j - s_k, \text{sign}(y_j - y_k)) 
\end{align*}
for some $\phi'$.
The pairwise approach attempts to reduce the problem of
ranking to the problem of classifying a pair as $\pm 1$ (i.e.,
when an object should be preferred over another). Some choices of $\phi'$
are the hinge loss of Ranking SVM~\cite{ranksvm}
($\phi'(s, y) = \1_{y < 0}(1 - s)_+$),
exponential loss of RankBoost~\cite{rankboost},
and the logistic loss of RankNet~\cite{}.
It is instructive to review how the logistic loss of RankNet is derived.
First, formulate a probabilistic model for the probability
of a pair $(x_j, x_k)$ receiving the label $+1$, based on the function's
output. Then think of the labels $\text{sign}(y_j - y_k)$
for this pair as coming from the underlying distribution that we are learning.
We want the distribution induced by the function's output to be similar to the
underlying distribution, so it makes sense to take $\phi'$ as the KL-divergence
\begin{align*}
  \phi'(s_j - s_k, \text{sign}(y_j - y_k))
  = \text{KL}(\Pr[\text{$(x_j, x_k)$ has label $1$} ; s_j - s_k], \Pr[\text{$(x_j, x_k)$ has label $1$} ; \text{sign}(y_j - y_k)]).
\end{align*}
RankNet uses the probabilistic models
\begin{align*}
  \Pr[\text{$(x_j, x_k)$ has label $+1$}; s_j - s_k] &= \frac{1}{1 + e^{-(s_j - s_k)}} \\
  \Pr[\text{$(x_j, x_k)$ has label $+1$} ; \text{sign}(y_j - y_k)] &=
  \begin{cases}
    1 & \text{sign}(y_j - y_k) = 1 \\
    \frac{1}{2} & \text{sign}(y_j - y_k) = 0 \\
    0 & \text{sign}(y_j - y_k) = -1
  \end{cases}
\end{align*}
(The latter can be changed to a proportion over the training set.)

Work in~\cite{ranking-measures-and-loss-functions} showed that Ranking SVM,
RankBoost, and RankNet all minimize $1 - \text{NDCG}(\vec{s}, y)$, but
Xia et.\ al.\ showed that Ranking SVM and RankBoost are in fact inconsistent,
even under the low-noise assumption~\cite{xia2008listwise}.

Importantly, RankNet minimizes the loss by doing gradient descent, which is
essentially about improving the ranking model in an appropriate way. Considering
that NDCG places more weight on doing well near the top of the list compared to
below, one may design a heuristic gradient that places more weight on improving
performance near the top. This is the idea behind LambdaRank~\cite{lambda-rank},
which scales the gradient in RankNet by the change in NDCG. 
According to a recent cross-benchmark survey of ranking
algorithms~\cite{cross-benchmark}, LambdaRank-inspired algorithms are
state-of-the-art. Unfortunately, the loss function behind this heuristic
gradient was implicit and hence not well-understood for some time, until recent
work this year makes this loss explicit using a probabilistic model~\cite{cikm}.
However, it is still unclear whether this surrogate is consistent; this is an
avenue for future research. 

TODO: ListNet.
